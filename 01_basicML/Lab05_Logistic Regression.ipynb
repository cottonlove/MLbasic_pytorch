{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch05Logistic Regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOiCPR0j0jTV9c83V5NOkp2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Rogistic Regression: 이진 분류 수행하는 모델\n","\n","둘 중하나를 결정하는 Binary Classification을 위한 대표적인 알고리즘\n"],"metadata":{"id":"o9a5aT-nr2Vm"}},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SAZB2ic3rxvM","executionInfo":{"status":"ok","timestamp":1643092329809,"user_tz":-540,"elapsed":233,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"99f3a6c6-3c8c-498e-f6ac-2b024283a304"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([6, 2])\n","torch.Size([6, 1])\n","torch.Size([6, 1])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)"]},"metadata":{},"execution_count":9}],"source":["#import\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","#for reporducibility (다른 곳에서 돌려도 같은 결과 나오게)\n","torch.manual_seed(1)\n","\n","#Training Data\n","x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]] #|x_data| = (6,2)  m=6, d=2\n","y_data = [[0], [0],[0], [1],[1],[1]] #|y_data| = (6,)\n","\n","#array -> torch.Tensor format으로 바꾸기!!!\n","x_train = torch.FloatTensor(x_data)\n","y_train = torch.FloatTensor(y_data)\n","\n","print(x_train.shape)\n","print(y_train.shape)\n","\n","#가중치 초기화 및 선언\n","W = torch.zeros((2,1), requires_grad=True)\n","b = torch.zeros(1, requires_grad = True)\n","\n","#hypothesis\n","'''hypothesis = 1/(1+torch.exp(-(x_train.matmul(W) + b)))'''\n","hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n","#x.matmul(w) = torch.matmul(x,w)\n","#print(hypothesis)\n","print(hypothesis.shape)\n","\n","#Computing Cost function\n","'''\n","#오차\n","losses = -(y_train * torch.log(hypothesis)+(1-y_train)* toch.log(1-hypothesis))\n","print(losses)\n","#전체 오차 평균\n","cost = losses.mean()\n","지금까지 비용 함수의 값을 직접 구현하였는데, 사실 파이토치에서는 로지스틱 회귀의 비용 함수를 이미 구현해서 제공하고 있습니다.\n","'''\n","F.binary_cross_entropy(hypothesis, y_train)\n","\n"]},{"cell_type":"markdown","source":["Whole Training Procedure\n","\n","```\n","# 코드로 형식 지정됨\n","```\n","\n"],"metadata":{"id":"K5kxzXJI721P"}},{"cell_type":"code","source":["#optimizer설정\n","optimizer = optim.SGD([W,b], lr = 1)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","  #Cost 계산\n","  hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n","  cost = F.binary_cross_entropy(hypothesis, y_train)\n","\n","  #Cost로 H(x)=P(y=1; W)개선\n","  optimizer.zero_grad() #gradeient초기화 꼭 하기\n","  cost.backward()\n","  optimizer.step()\n","\n","  #100번마다 로그 출력\n","  if epoch % 100 == 0:\n","    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, cost.item()\n","    ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bRgJnGM_74yF","executionInfo":{"status":"ok","timestamp":1643092608800,"user_tz":-540,"elapsed":666,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"f96f7608-81fd-4563-d1e1-8dc09462b562"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/1000 Cost: 0.693147\n","Epoch  100/1000 Cost: 0.134722\n","Epoch  200/1000 Cost: 0.080643\n","Epoch  300/1000 Cost: 0.057900\n","Epoch  400/1000 Cost: 0.045300\n","Epoch  500/1000 Cost: 0.037261\n","Epoch  600/1000 Cost: 0.031672\n","Epoch  700/1000 Cost: 0.027556\n","Epoch  800/1000 Cost: 0.024394\n","Epoch  900/1000 Cost: 0.021888\n","Epoch 1000/1000 Cost: 0.019852\n"]}]},{"cell_type":"markdown","source":["Evaluation\n","\n","hypothesis = p(y=1 ; W)"],"metadata":{"id":"1wFDku--86ro"}},{"cell_type":"code","source":["hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n","print(hypothesis)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EHKi1GLZ9A2p","executionInfo":{"status":"ok","timestamp":1643092819031,"user_tz":-540,"elapsed":293,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"8eba6b0d-e8df-4965-b16b-0e41889f72e5"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[2.7648e-04],\n","        [3.1608e-02],\n","        [3.8977e-02],\n","        [9.5622e-01],\n","        [9.9823e-01],\n","        [9.9969e-01]], grad_fn=<SigmoidBackward0>)\n"]}]},{"cell_type":"markdown","source":["현재 위 값들은 0과 1 사이의 값을 가지고 있습니다. 이제 0.5를 넘으면 True, 넘지 않으면 False로 값을 정하여 출력해보겠습니다."],"metadata":{"id":"WmWoJRqZ9ajx"}},{"cell_type":"code","source":["prediction = hypothesis >= torch.FloatTensor([0.5])\n","print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IIDI1qGz9e8O","executionInfo":{"status":"ok","timestamp":1643092881980,"user_tz":-540,"elapsed":248,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"d2bb2575-faa4-47e6-bf52-62108010d942"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[False],\n","        [False],\n","        [False],\n","        [ True],\n","        [ True],\n","        [ True]])\n"]}]},{"cell_type":"code","source":["correct_prediction = prediction.float() == y_train\n","print(correct_prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"atohaVym9uGW","executionInfo":{"status":"ok","timestamp":1643092868372,"user_tz":-540,"elapsed":264,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"85477a91-6f83-43e2-ddea-98f79d6f7786"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[True],\n","        [True],\n","        [True],\n","        [True],\n","        [True],\n","        [True]])\n"]}]},{"cell_type":"code","source":["print(\"After Training, W is {} b is {}\".format(W,b))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxx3vUzw99yo","executionInfo":{"status":"ok","timestamp":1643092921574,"user_tz":-540,"elapsed":257,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"3ab15f3c-9d5e-4e49-fc4f-ca752d54480b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["After Training, W is tensor([[3.2530],\n","        [1.5179]], requires_grad=True) b is tensor([-14.4819], requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["Higher Implementation with Class"],"metadata":{"id":"C8e1sCAB-hQM"}},{"cell_type":"markdown","source":["위와 같은 클래스를 사용한 모델 구현 형식은 대부분의 파이토치 구현체에서 사용하고 있는 방식으로 반드시 숙지할 필요가 있습니다.\n","\n","클래스(class) 형태의 모델은 nn.Module 을 상속받습니다. 그리고 __init__()에서 모델의 구조와 동적을 정의하는 생성자를 정의합니다. 이는 파이썬에서 객체가 갖는 속성값을 초기화하는 역할로, 객체가 생성될 때 자동으호 호출됩니다. super() 함수를 부르면 여기서 만든 클래스는 nn.Module 클래스의 속성들을 가지고 초기화 됩니다. \n","\n","foward() 함수는 모델이 학습데이터를 입력받아서 forward 연산을 진행시키는 함수입니다. 이 forward() 함수는 model 객체를 데이터와 함께 호출하면 자동으로 실행이됩니다. 예를 들어 model이란 이름의 객체를 생성 후, model(입력 데이터)와 같은 형식으로 객체를 호출하면 자동으로 forward 연산이 수행됩니다.\n","\n","H(x) 식에 입력 로부터 예측된 를 얻는 것을 forward 연산이라고 합니다."],"metadata":{"id":"iO5w9T1iAwLj"}},{"cell_type":"code","source":["\n","class BinaryClassifier(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.linear = nn.Linear(2,1) #input_dim = 2, output_dim = 1 <-> |x|=(?,2) |W| = (2,1), |b| = (1,)\n","    self.sigmoid = nn.Sigmoid()\n","  \n","  def forward(self, x):\n","    return self.sigmoid(self.linear(x))\n","\n","#model 선언\n","model = BinaryClassifier()\n","\n","#optimizer선언\n","optimizer = optim.SGD(model.parameters(), lr = 1) #model.parameters()를 통해, W, b가 iterator형식으로 들어옴\n","\n","nb_epochs = 100\n","for epoch in range(nb_epochs + 1):\n","  #H(x) = P(y=1; W) 계산\n","  hypothesis = model(x_train)\n","\n","  #cost 계산\n","  cost = F.binary_cross_entropy(hypothesis, y_train)\n","\n","  #cost로 H(x) 개선\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","\n","  #20번마다 로그 출력\n","  if epoch % 10 == 0:\n","        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n","        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n","        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n","        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n","            epoch, nb_epochs, cost.item(), accuracy * 100,\n","        ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WuquiOr-l8O","executionInfo":{"status":"ok","timestamp":1643093549163,"user_tz":-540,"elapsed":267,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"eb9d1c69-536c-4595-fa96-1811137c084f"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/100 Cost: 0.734527 Accuracy 50.00%\n","Epoch   10/100 Cost: 0.446570 Accuracy 66.67%\n","Epoch   20/100 Cost: 0.448868 Accuracy 66.67%\n","Epoch   30/100 Cost: 0.375859 Accuracy 83.33%\n","Epoch   40/100 Cost: 0.318583 Accuracy 83.33%\n","Epoch   50/100 Cost: 0.268096 Accuracy 83.33%\n","Epoch   60/100 Cost: 0.222295 Accuracy 100.00%\n","Epoch   70/100 Cost: 0.183465 Accuracy 100.00%\n","Epoch   80/100 Cost: 0.158036 Accuracy 100.00%\n","Epoch   90/100 Cost: 0.144541 Accuracy 100.00%\n","Epoch  100/100 Cost: 0.134652 Accuracy 100.00%\n"]}]},{"cell_type":"markdown","source":["nn.Module로 구현하는 Logistic Regression"],"metadata":{"id":"6wqOJ-7hBt1C"}},{"cell_type":"code","source":["model = nn.Sequential(nn.Linear(2,1), # input_dim = 2, output_dim = 1\n","                      nn.Sigmoid() # 출력은 시그모이드 함수를 거친다\n","                      )\n","\n","model(x_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nfUfa2cBzxM","executionInfo":{"status":"ok","timestamp":1643093944533,"user_tz":-540,"elapsed":17,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"0603e262-379b-439b-8d82-fa66dae18e53"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4147],\n","        [0.4105],\n","        [0.6101],\n","        [0.5386],\n","        [0.6018],\n","        [0.7205]], grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# optimizer 설정\n","optimizer = optim.SGD(model.parameters(), lr=1)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","\n","    # H(x) 계산\n","    hypothesis = model(x_train)\n","\n","    # cost 계산\n","    cost = F.binary_cross_entropy(hypothesis, y_train)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 20번마다 로그 출력\n","    if epoch % 10 == 0:\n","        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n","        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n","        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n","        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n","            epoch, nb_epochs, cost.item(), accuracy * 100,\n","        ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9po2C-_QCESg","executionInfo":{"status":"ok","timestamp":1643093971324,"user_tz":-540,"elapsed":678,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"b51ea37e-3de0-4f7d-f807-a76709d21f94"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/1000 Cost: 0.576740 Accuracy 83.33%\n","Epoch   10/1000 Cost: 0.818109 Accuracy 66.67%\n","Epoch   20/1000 Cost: 0.582192 Accuracy 83.33%\n","Epoch   30/1000 Cost: 0.488437 Accuracy 83.33%\n","Epoch   40/1000 Cost: 0.402663 Accuracy 83.33%\n","Epoch   50/1000 Cost: 0.321072 Accuracy 83.33%\n","Epoch   60/1000 Cost: 0.247059 Accuracy 83.33%\n","Epoch   70/1000 Cost: 0.190018 Accuracy 100.00%\n","Epoch   80/1000 Cost: 0.158865 Accuracy 100.00%\n","Epoch   90/1000 Cost: 0.144834 Accuracy 100.00%\n","Epoch  100/1000 Cost: 0.134897 Accuracy 100.00%\n","Epoch  110/1000 Cost: 0.126315 Accuracy 100.00%\n","Epoch  120/1000 Cost: 0.118780 Accuracy 100.00%\n","Epoch  130/1000 Cost: 0.112109 Accuracy 100.00%\n","Epoch  140/1000 Cost: 0.106162 Accuracy 100.00%\n","Epoch  150/1000 Cost: 0.100828 Accuracy 100.00%\n","Epoch  160/1000 Cost: 0.096016 Accuracy 100.00%\n","Epoch  170/1000 Cost: 0.091653 Accuracy 100.00%\n","Epoch  180/1000 Cost: 0.087679 Accuracy 100.00%\n","Epoch  190/1000 Cost: 0.084043 Accuracy 100.00%\n","Epoch  200/1000 Cost: 0.080704 Accuracy 100.00%\n","Epoch  210/1000 Cost: 0.077627 Accuracy 100.00%\n","Epoch  220/1000 Cost: 0.074782 Accuracy 100.00%\n","Epoch  230/1000 Cost: 0.072143 Accuracy 100.00%\n","Epoch  240/1000 Cost: 0.069688 Accuracy 100.00%\n","Epoch  250/1000 Cost: 0.067399 Accuracy 100.00%\n","Epoch  260/1000 Cost: 0.065259 Accuracy 100.00%\n","Epoch  270/1000 Cost: 0.063254 Accuracy 100.00%\n","Epoch  280/1000 Cost: 0.061372 Accuracy 100.00%\n","Epoch  290/1000 Cost: 0.059601 Accuracy 100.00%\n","Epoch  300/1000 Cost: 0.057931 Accuracy 100.00%\n","Epoch  310/1000 Cost: 0.056355 Accuracy 100.00%\n","Epoch  320/1000 Cost: 0.054863 Accuracy 100.00%\n","Epoch  330/1000 Cost: 0.053451 Accuracy 100.00%\n","Epoch  340/1000 Cost: 0.052111 Accuracy 100.00%\n","Epoch  350/1000 Cost: 0.050838 Accuracy 100.00%\n","Epoch  360/1000 Cost: 0.049627 Accuracy 100.00%\n","Epoch  370/1000 Cost: 0.048473 Accuracy 100.00%\n","Epoch  380/1000 Cost: 0.047373 Accuracy 100.00%\n","Epoch  390/1000 Cost: 0.046322 Accuracy 100.00%\n","Epoch  400/1000 Cost: 0.045319 Accuracy 100.00%\n","Epoch  410/1000 Cost: 0.044358 Accuracy 100.00%\n","Epoch  420/1000 Cost: 0.043438 Accuracy 100.00%\n","Epoch  430/1000 Cost: 0.042556 Accuracy 100.00%\n","Epoch  440/1000 Cost: 0.041710 Accuracy 100.00%\n","Epoch  450/1000 Cost: 0.040897 Accuracy 100.00%\n","Epoch  460/1000 Cost: 0.040116 Accuracy 100.00%\n","Epoch  470/1000 Cost: 0.039365 Accuracy 100.00%\n","Epoch  480/1000 Cost: 0.038642 Accuracy 100.00%\n","Epoch  490/1000 Cost: 0.037945 Accuracy 100.00%\n","Epoch  500/1000 Cost: 0.037274 Accuracy 100.00%\n","Epoch  510/1000 Cost: 0.036626 Accuracy 100.00%\n","Epoch  520/1000 Cost: 0.036000 Accuracy 100.00%\n","Epoch  530/1000 Cost: 0.035396 Accuracy 100.00%\n","Epoch  540/1000 Cost: 0.034812 Accuracy 100.00%\n","Epoch  550/1000 Cost: 0.034248 Accuracy 100.00%\n","Epoch  560/1000 Cost: 0.033701 Accuracy 100.00%\n","Epoch  570/1000 Cost: 0.033172 Accuracy 100.00%\n","Epoch  580/1000 Cost: 0.032660 Accuracy 100.00%\n","Epoch  590/1000 Cost: 0.032163 Accuracy 100.00%\n","Epoch  600/1000 Cost: 0.031682 Accuracy 100.00%\n","Epoch  610/1000 Cost: 0.031214 Accuracy 100.00%\n","Epoch  620/1000 Cost: 0.030761 Accuracy 100.00%\n","Epoch  630/1000 Cost: 0.030321 Accuracy 100.00%\n","Epoch  640/1000 Cost: 0.029893 Accuracy 100.00%\n","Epoch  650/1000 Cost: 0.029477 Accuracy 100.00%\n","Epoch  660/1000 Cost: 0.029073 Accuracy 100.00%\n","Epoch  670/1000 Cost: 0.028680 Accuracy 100.00%\n","Epoch  680/1000 Cost: 0.028298 Accuracy 100.00%\n","Epoch  690/1000 Cost: 0.027925 Accuracy 100.00%\n","Epoch  700/1000 Cost: 0.027563 Accuracy 100.00%\n","Epoch  710/1000 Cost: 0.027210 Accuracy 100.00%\n","Epoch  720/1000 Cost: 0.026866 Accuracy 100.00%\n","Epoch  730/1000 Cost: 0.026530 Accuracy 100.00%\n","Epoch  740/1000 Cost: 0.026203 Accuracy 100.00%\n","Epoch  750/1000 Cost: 0.025884 Accuracy 100.00%\n","Epoch  760/1000 Cost: 0.025573 Accuracy 100.00%\n","Epoch  770/1000 Cost: 0.025269 Accuracy 100.00%\n","Epoch  780/1000 Cost: 0.024972 Accuracy 100.00%\n","Epoch  790/1000 Cost: 0.024683 Accuracy 100.00%\n","Epoch  800/1000 Cost: 0.024400 Accuracy 100.00%\n","Epoch  810/1000 Cost: 0.024123 Accuracy 100.00%\n","Epoch  820/1000 Cost: 0.023853 Accuracy 100.00%\n","Epoch  830/1000 Cost: 0.023589 Accuracy 100.00%\n","Epoch  840/1000 Cost: 0.023330 Accuracy 100.00%\n","Epoch  850/1000 Cost: 0.023078 Accuracy 100.00%\n","Epoch  860/1000 Cost: 0.022830 Accuracy 100.00%\n","Epoch  870/1000 Cost: 0.022588 Accuracy 100.00%\n","Epoch  880/1000 Cost: 0.022352 Accuracy 100.00%\n","Epoch  890/1000 Cost: 0.022120 Accuracy 100.00%\n","Epoch  900/1000 Cost: 0.021893 Accuracy 100.00%\n","Epoch  910/1000 Cost: 0.021670 Accuracy 100.00%\n","Epoch  920/1000 Cost: 0.021452 Accuracy 100.00%\n","Epoch  930/1000 Cost: 0.021239 Accuracy 100.00%\n","Epoch  940/1000 Cost: 0.021029 Accuracy 100.00%\n","Epoch  950/1000 Cost: 0.020824 Accuracy 100.00%\n","Epoch  960/1000 Cost: 0.020623 Accuracy 100.00%\n","Epoch  970/1000 Cost: 0.020426 Accuracy 100.00%\n","Epoch  980/1000 Cost: 0.020232 Accuracy 100.00%\n","Epoch  990/1000 Cost: 0.020042 Accuracy 100.00%\n","Epoch 1000/1000 Cost: 0.019856 Accuracy 100.00%\n"]}]},{"cell_type":"code","source":["model(x_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGZnBuF-CI0N","executionInfo":{"status":"ok","timestamp":1643093991779,"user_tz":-540,"elapsed":262,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"2304108b-0d08-42d4-881e-a00631117846"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2.7660e-04],\n","        [3.1613e-02],\n","        [3.8984e-02],\n","        [9.5621e-01],\n","        [9.9823e-01],\n","        [9.9969e-01]], grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["print(list(model.parameters()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdIClhDKCMZv","executionInfo":{"status":"ok","timestamp":1643094006127,"user_tz":-540,"elapsed":5,"user":{"displayName":"박윤정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07255778251027257626"}},"outputId":"ab862bd0-07e1-4617-c6ff-f7b9d2cb4f7d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[3.2528, 1.5178]], requires_grad=True), Parameter containing:\n","tensor([-14.4811], requires_grad=True)]\n"]}]}]}